# RAG Service - Retrieval-Augmented Generation Multi-Provider

## Vis√£o Geral

O RAG Service √© o sistema de recupera√ß√£o aumentada por gera√ß√£o que enriquece os agentes de IA com conhecimento jur√≠dico especializado. Implementa uma **arquitetura multi-provider** que permite usar diferentes servi√ßos de embeddings (Gemini, OpenAI, Anthropic) com fallback autom√°tico.

**‚ú® Novidade**: Implementa√ß√£o multi-provider com suporte a Google Gemini (gratuito), OpenAI (alta qualidade) e Anthropic/Voyage AI (especializado em dom√≠nio legal).

## Arquitetura Multi-Provider

### Componentes Principais

1. **Vector Database (pg_vector)**: Armazena embeddings de documentos legais
2. **Multi-Provider Engine**: Sistema de embeddings com fallback autom√°tico
3. **Legal Documents**: Leis, regulamentos, jurisprud√™ncia indexada
4. **Knowledge Base**: Diretrizes e melhores pr√°ticas
5. **Context Builder**: Constr√≥i contexto relevante para agentes
6. **Search Service**: Busca por similaridade vetorial

### Providers Dispon√≠veis

#### ü•á Google Gemini (Default)
- **Modelo**: `models/embedding-001`
- **Dimens√µes**: 768
- **Custo**: Gratuito (com limites)
- **Vantagens**: 
  - √ìtimo para portugu√™s brasileiro
  - Gratuito no free tier
  - Boa performance em textos jur√≠dicos
- **Limites Free Tier**:
  - 1,500 requests/dia
  - 15 requests/minuto
- **Status**: ‚úÖ Implementado e testado

#### ü•à OpenAI (Fallback)
- **Modelo**: `text-embedding-3-small`
- **Dimens√µes**: 1536
- **Custo**: Pago ($0.02 / 1M tokens)
- **Vantagens**:
  - Melhor qualidade geral
  - Mais dimens√µes (1536)
  - API est√°vel e r√°pida
- **Status**: ‚úÖ Implementado, aguardando OPENAI_API_KEY

#### ü•â Anthropic/Voyage AI (Futuro)
- **Modelo**: Voyage AI (especializado)
- **Dimens√µes**: 1024
- **Custo**: A definir
- **Vantagens**:
  - Especializado em dom√≠nio legal
  - Alta precis√£o para contratos
- **Status**: üîÑ Placeholder implementado

### Fluxo de Dados

```
Consulta ‚Üí [Provider Selection] ‚Üí Embedding ‚Üí Busca Vetorial ‚Üí Contexto ‚Üí Agente ‚Üí An√°lise Enriquecida
                ‚Üì
         Gemini > OpenAI > Anthropic
```

### Auto-Sele√ß√£o de Provider

O sistema seleciona automaticamente o melhor provider dispon√≠vel:

```python
Priority Chain:
1. Gemini (se GOOGLE_API_KEY dispon√≠vel) ‚Üí Free + Bom para PT-BR
2. OpenAI (se OPENAI_API_KEY dispon√≠vel) ‚Üí Melhor qualidade
3. Anthropic (placeholder) ‚Üí Futuro especializado

Fallback autom√°tico se quota excedida ou API indispon√≠vel
```

## Configura√ß√£o do Banco

### 1. Habilitar pg_vector

```sql
-- No PostgreSQL (Supabase)
CREATE EXTENSION IF NOT EXISTS vector;
```

### 2. Executar Migrations

```bash
cd backend
alembic upgrade head
```

### 3. Verificar Tabelas

- `legal_documents`: Documentos legais completos
- `legal_chunks`: Chunks dos documentos com embeddings
- `knowledge_base`: Diretrizes e melhores pr√°ticas

## Configura√ß√£o de Ambiente

### Vari√°veis de API Keys

O sistema suporta m√∫ltiplos providers. Configure pelo menos um:

```env
# Op√ß√£o 1: Google Gemini (Recomendado para come√ßar - FREE)
GOOGLE_API_KEY=your_google_api_key_here

# Op√ß√£o 2: OpenAI (Melhor qualidade - PAGO)
OPENAI_API_KEY=your_openai_api_key_here

# Op√ß√£o 3: Anthropic (Futuro - especializado legal)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
```

### Como Obter API Keys

#### Google Gemini (Gratuito)
1. Acesse: https://makersuite.google.com/app/apikey
2. Clique em "Create API Key"
3. Copie a key e adicione no `.env`
4. **Limites Free**: 1,500 requests/dia, 15/minuto

#### OpenAI (Pago)
1. Acesse: https://platform.openai.com/api-keys
2. Clique em "Create new secret key"
3. Copie a key e adicione no `.env`
4. **Custo**: ~$0.02 por 1M tokens

#### Anthropic (Futuro)
1. Em breve: integra√ß√£o com Voyage AI
2. Embeddings especializados em documentos legais

## Instala√ß√£o de Depend√™ncias

### Pacotes Python Necess√°rios

```bash
# Instalar todos os providers
pip install google-generativeai anthropic openai

# Ou apenas o que voc√™ vai usar:
pip install google-generativeai  # Para Gemini
pip install openai                # Para OpenAI
pip install anthropic             # Para Anthropic (futuro)
```

### Verificar Instala√ß√£o

```python
# Test script
python -c "import google.generativeai; import anthropic; print('‚úÖ Packages OK')"
```

## Uso Program√°tico

### Exemplo B√°sico - Auto-Sele√ß√£o de Provider

```python
from app.services.rag_service import get_rag_service

# O sistema escolhe automaticamente o melhor provider dispon√≠vel
rag = get_rag_service()

# Criar embeddings
texts = [
    "Contrato de loca√ß√£o com cl√°usula abusiva",
    "Multa por rescis√£o antecipada de 3 meses"
]

embeddings = await rag.create_embeddings(texts)
print(f"Provider usado: {rag.provider}")  # gemini, openai ou anthropic
print(f"Dimens√µes: {len(embeddings[0])}")  # 768, 1536 ou 1024
```

### Exemplo Avan√ßado - Provider Espec√≠fico

```python
from app.services.rag_service import RAGService, EmbeddingProvider

# For√ßar uso do Gemini
rag_gemini = RAGService(provider=EmbeddingProvider.GEMINI)

# For√ßar uso do OpenAI (se dispon√≠vel)
rag_openai = RAGService(provider=EmbeddingProvider.OPENAI)

# Verificar qual provider est√° ativo
print(f"Provider: {rag_gemini.provider.value}")
print(f"Model: {rag_gemini.embedding_model}")
print(f"Dimensions: {rag_gemini.embedding_dimension}")
```

### Busca Sem√¢ntica com RAG

```python
from app.services.rag_service import get_rag_service
from app.db.session import get_session

async def search_legal_knowledge():
    rag = get_rag_service()
    
    async with get_session() as db:
        results = await rag.search_legal_knowledge(
            query="cl√°usulas abusivas em contratos de loca√ß√£o",
            contract_category="locacao",
            document_types=["lei", "jurisprudencia"],
            authority_level="high",
            limit=10,
            similarity_threshold=0.75,
            db=db
        )
    
    print(f"Found {len(results['legal_chunks'])} relevant chunks")
    for chunk in results['legal_chunks']:
        print(f"- {chunk.content[:100]}... (similarity: {chunk.similarity:.2f})")
```

### Tratamento de Erros e Fallback

```python
from app.services.rag_service import get_rag_service
from google.api_core.exceptions import ResourceExhausted

async def safe_embedding_creation(texts):
    """Cria√ß√£o de embeddings com tratamento de quota"""
    rag = get_rag_service()
    
    try:
        embeddings = await rag.create_embeddings(texts)
        return embeddings
    
    except ResourceExhausted:
        # Quota do Gemini excedida
        print("‚ö†Ô∏è Gemini quota exceeded, sistema tentar√° fallback autom√°tico")
        
        # Se tiver OpenAI configurado, o sistema usa automaticamente
        # Caso contr√°rio, voc√™ pode configurar OpenAI:
        # 1. Adicione OPENAI_API_KEY no .env
        # 2. Reinicie o servi√ßo
        # 3. Sistema far√° fallback automaticamente
        
        raise Exception("Configure OPENAI_API_KEY para fallback autom√°tico")
```

## Compara√ß√£o de Providers

### Performance Benchmark

| Provider | Dimens√µes | Custo/1M tokens | Tempo/embed | Qualidade PT-BR |
|----------|-----------|-----------------|-------------|-----------------|
| **Gemini** | 768 | üÜì Gratuito* | ~0.3s | ‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| **OpenAI** | 1536 | $0.02 | ~0.1s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Superior |
| **Anthropic** | 1024 | TBD | TBD | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Legal-specific |

*Sujeito a limites: 1,500/dia, 15/minuto no free tier

### Quando Usar Cada Provider

#### Use Gemini quando:
- ‚úÖ Come√ßando o projeto (gratuito)
- ‚úÖ Desenvolvimento e testes
- ‚úÖ Volume moderado (< 1,500 requests/dia)
- ‚úÖ Textos em portugu√™s brasileiro
- ‚úÖ Or√ßamento limitado

#### Use OpenAI quando:
- ‚úÖ Produ√ß√£o com alto volume
- ‚úÖ M√°xima qualidade necess√°ria
- ‚úÖ Or√ßamento dispon√≠vel
- ‚úÖ Busca mais precisa
- ‚úÖ Quota do Gemini excedida

#### Use Anthropic quando:
- ‚úÖ Dom√≠nio legal espec√≠fico (futuro)
- ‚úÖ An√°lise de contratos complexos
- ‚úÖ Necessita embeddings especializados

## Indexa√ß√£o de Conhecimento

### Executar Indexa√ß√£o Inicial

```bash
cd backend
python -m app.workers.legal_indexer
```

### Documentos Inclu√≠dos

- Lei do Inquilinato (8.245/91)
- C√≥digo de Defesa do Consumidor
- Regulamenta√ß√£o ANATEL
- C√≥digo Civil - Contratos
- Jurisprud√™ncia STJ relevante

## API Endpoints

### Busca no Knowledge Base

```http
POST /api/v1/contracts/rag/search
Content-Type: application/json

{
  "query": "cl√°usula de multa contrato loca√ß√£o",
  "contract_category": "locacao", 
  "document_types": ["lei", "jurisprudencia"],
  "authority_level": "high",
  "limit": 10,
  "similarity_threshold": 0.75
}
```

### An√°lise Enriquecida

```http
POST /api/v1/contracts/{contract_id}/enhanced-analysis
Content-Type: application/json

{
  "contract_text": "texto do contrato...",
  "contract_category": "locacao",
  "analysis_type": "risk_assessment"
}
```

### Precedentes Legais

```http
POST /api/v1/contracts/legal-precedents
Content-Type: application/json

{
  "contract_clause": "multa compensat√≥ria tr√™s alugu√©is",
  "contract_type": "locacao"
}
```

### Estat√≠sticas

```http
GET /api/v1/contracts/rag/stats
```

## Uso nos Agentes

### Integra√ß√£o B√°sica

```python
from app.agents.rental_agent import RentalAgent
from app.services.rag_service import rag_service

# Criar agente com RAG
agent = RentalAgent(claude_client, rag_service, db_session)

# An√°lise com contexto enriquecido
analysis = await agent.analyze_contract(contract_text)
```

### Contexto Enriquecido

```python
# Obter contexto legal relevante
enriched_context = await agent.get_enriched_context(
    contract_text, 
    analysis_type="risk_assessment"
)

# Precedentes para cl√°usula espec√≠fica
precedents = await agent.get_legal_precedents(
    "cl√°usula de multa compensat√≥ria"
)
```

## Tipos de An√°lise

### 1. An√°lise de Risco (`risk_assessment`)
- Identifica cl√°usulas de alto risco
- Compara com precedentes jurisprudenciais
- Sugere mitiga√ß√µes

### 2. An√°lise de Conformidade (`compliance_analysis`) 
- Verifica conformidade com legisla√ß√£o
- Identifica cl√°usulas potencialmente ilegais
- Sugere adequa√ß√µes

### 3. An√°lise Comparativa (`comparative_analysis`)
- Compara com padr√µes de mercado
- Identifica cl√°usulas at√≠picas
- Sugere melhorias

## Categorias Suportadas

### Contratos de Loca√ß√£o (`locacao`)
- Lei do Inquilinato (8.245/91)
- Jurisprud√™ncia espec√≠fica
- Melhores pr√°ticas de mercado

### Telecomunica√ß√µes (`telecom`)
- Regulamenta√ß√£o ANATEL
- Direitos dos usu√°rios
- Cl√°usulas t√≠picas abusivas

### Financeiro (`financeiro`)
- Regulamenta√ß√£o BACEN
- C√≥digo de Defesa do Consumidor
- Limites legais de juros

### Geral (`geral`)
- C√≥digo Civil
- Princ√≠pios contratuais
- Direitos fundamentais

## Troubleshooting

### Erro: "Quota exceeded" (Gemini)

**Problema**: Quota do Gemini Free Tier excedida

```
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota
```

**Solu√ß√µes**:

1. **Op√ß√£o A - Aguardar reset** (recomendado para dev):
   - Quota di√°ria: Reset √† meia-noite (PST)
   - Quota por minuto: Reset ap√≥s 60 segundos

2. **Op√ß√£o B - Configurar OpenAI** (recomendado para prod):
   ```bash
   # Adicione no .env
   OPENAI_API_KEY=sk-your-key-here
   
   # Reinicie o servi√ßo
   # Sistema far√° fallback autom√°tico para OpenAI
   ```

3. **Op√ß√£o C - Upgrade Gemini** (futuro):
   - Google oferecer√° plano pago com quotas maiores

### Erro: "GOOGLE_API_KEY not found"

**Problema**: API key n√£o configurada

**Solu√ß√£o**:
```bash
# 1. Obtenha a key em https://makersuite.google.com/app/apikey
# 2. Adicione no backend/.env
echo "GOOGLE_API_KEY=your_key_here" >> backend/.env

# 3. Reinicie o servidor
cd backend
python -m uvicorn main:app --reload
```

### Erro: "Import google.generativeai could not be resolved"

**Problema**: Pacote n√£o instalado

**Solu√ß√£o**:
```bash
pip install google-generativeai anthropic
```

### Embeddings com Dimens√µes Erradas

**Problema**: Mistura de embeddings de providers diferentes

**Sintomas**:
- Busca vetorial retorna resultados irrelevantes
- Erro: "dimension mismatch" no pg_vector

**Solu√ß√£o**: Use o script de migra√ß√£o (ver se√ß√£o abaixo)

### Performance Lenta

**Problema**: Embeddings demorando muito

**Diagn√≥stico**:
```python
import time
from app.services.rag_service import get_rag_service

rag = get_rag_service()
start = time.time()
await rag.create_embeddings(["test"])
print(f"Time: {time.time() - start:.2f}s")
```

**Solu√ß√µes**:
- **Gemini**: ~0.3s/embedding (sequencial)
- **OpenAI**: ~0.1s/embedding (batch de 100)
- Para alto volume, use OpenAI

## Melhores Pr√°ticas

### 1. Lazy Initialization

```python
# ‚úÖ CORRETO: Usa get_rag_service()
from app.services.rag_service import get_rag_service

rag = get_rag_service()  # Lazy loading
```

```python
# ‚ùå ERRADO: Importa√ß√£o global
from app.services.rag_service import rag_service  # Antigo, deprecated

# Causar√° erro se API key n√£o estiver configurada no startup
```

### 2. Batch Processing

```python
# ‚úÖ CORRETO: Processa em batch
texts = [...]  # 100 textos
embeddings = await rag.create_embeddings(texts)  # Uma chamada

# ‚ùå ERRADO: Um por um
for text in texts:
    emb = await rag.create_embeddings([text])  # 100 chamadas!
```

### 3. Cache de Embeddings

```python
# ‚úÖ CORRETO: Cache em database
async def get_cached_embedding(text: str, db):
    # Verifica se j√° existe
    cached = await db.query(LegalChunk).filter_by(content=text).first()
    if cached:
        return cached.embedding
    
    # Se n√£o existe, cria e salva
    embedding = await rag.create_embeddings([text])
    chunk = LegalChunk(content=text, embedding=embedding[0])
    db.add(chunk)
    await db.commit()
    return embedding[0]
```

### 4. Tratamento de Erros

```python
# ‚úÖ CORRETO: Try/catch com fallback
try:
    embeddings = await rag.create_embeddings(texts)
except ResourceExhausted:
    # Log erro e tenta provider alternativo
    logger.warning("Gemini quota exceeded")
    # Sistema j√° tenta fallback autom√°tico
    raise
except Exception as e:
    logger.error(f"Embedding error: {e}")
    # Seu c√≥digo de recupera√ß√£o aqui
```

### 5. Monitoramento de Quota

```python
# Implementar contador de requests
import redis

async def check_gemini_quota():
    """Verifica se est√° pr√≥ximo do limite"""
    r = redis.Redis()
    count = r.incr('gemini_requests_today')
    r.expire('gemini_requests_today', 86400)  # 24h
    
    if count > 1400:  # 93% do limite de 1500
        logger.warning(f"Gemini quota quase excedida: {count}/1500")
        # Mudar para OpenAI
        return False
    return True
```

## Migra√ß√£o Entre Providers

Ver script detalhado em: `backend/scripts/migrate_embeddings.py`

### Cen√°rios de Migra√ß√£o

#### 1. Gemini ‚Üí OpenAI (Upgrade para Produ√ß√£o)

```bash
# Motivo: Maior qualidade e sem limites de quota
python backend/scripts/migrate_embeddings.py \
    --from gemini \
    --to openai \
    --batch-size 100
```

#### 2. OpenAI ‚Üí Gemini (Redu√ß√£o de Custos)

```bash
# Motivo: Economizar em ambiente de desenvolvimento
python backend/scripts/migrate_embeddings.py \
    --from openai \
    --to gemini \
    --batch-size 10  # Menor batch por causa do rate limit
```

#### 3. Qualquer ‚Üí Anthropic (Futu ro - Legal Specific)

```bash
# Quando Voyage AI estiver dispon√≠vel
python backend/scripts/migrate_embeddings.py \
    --from gemini \
    --to anthropic \
    --batch-size 50
```

### Valida√ß√£o P√≥s-Migra√ß√£o

```python
# Verificar consist√™ncia ap√≥s migra√ß√£o
from app.services.rag_service import get_rag_service

rag = get_rag_service()

# Test query
results = await rag.search_legal_knowledge(
    query="cl√°usula abusiva",
    db=db,
    limit=10
)

print(f"Found {len(results['legal_chunks'])} results")
# Se retornar 0 ou resultados irrelevantes, houve problema na migra√ß√£o
```

## M√©tricas de Qualidade

### Similarity Score
- `> 0.9`: Alta relev√¢ncia
- `0.7 - 0.9`: Relev√¢ncia m√©dia
- `< 0.7`: Baixa relev√¢ncia

### Authority Level
- `high`: STF, STJ, Leis federais
- `medium`: TJs, Regulamentos
- `low`: Doutrinas, Pareceres

## Testes

### Executar Testes

```bash
cd backend
python test_rag.py
```

### Verifica√ß√µes

1. ‚úÖ Cria√ß√£o de embeddings
2. ‚úÖ Adi√ß√£o ao knowledge base
3. ‚úÖ Busca por similaridade
4. ‚úÖ Indexa√ß√£o de documentos
5. ‚úÖ Constru√ß√£o de contexto

## Monitoramento

### M√©tricas Importantes

- N√∫mero de documentos indexados
- Tempo de resposta das buscas
- Qualidade dos similarity scores
- Taxa de uso por categoria

### Logs

```bash
# Ver logs do RAG Service
grep "RAGService" backend/logs/app.log

# Ver performance
grep "similarity_search" backend/logs/app.log
```

## Manuten√ß√£o

### Adicionar Novos Documentos

```python
# Via API ou script
await rag_service.index_legal_document(
    title="Nova Lei - Artigo X",
    content="conte√∫do da lei...",
    document_type="lei",
    category="locacao",
    source="Lei X/2024",
    authority_level="high"
)
```

### Atualizar Knowledge Base

```python
# Atualizar entrada existente
await rag_service.update_knowledge(
    knowledge_id="uuid",
    content="novo conte√∫do...",
    title="T√≠tulo Atualizado"
)
```

### Reindexar Documentos

```bash
# Reprocessar todos os documentos
python -m app.workers.legal_indexer --reindex-all
```

## Performance

### Otimiza√ß√µes Implementadas

- √çndices IVFFlat para busca vetorial r√°pida
- Chunking inteligente por par√°grafos
- Cache de embeddings
- Busca paralela por tipo de documento

### Configura√ß√µes Recomendadas

```python
# Configura√ß√µes √≥timas
CHUNK_SIZE = 1000        # Tamanho do chunk
CHUNK_OVERLAP = 200      # Sobreposi√ß√£o
EMBEDDING_DIMENSION = 1536  # OpenAI text-embedding-3-small
SIMILARITY_THRESHOLD = 0.75  # Limite de relev√¢ncia
```

## Roadmap

### Pr√≥ximas Funcionalidades

- [ ] Indexa√ß√£o autom√°tica de novas leis
- [ ] Cache inteligente de buscas
- [ ] An√°lise de sentimentos em jurisprud√™ncia
- [ ] Integra√ß√£o com sistemas jur√≠dicos externos
- [ ] Dashboard de analytics do RAG
- [ ] Fine-tuning de embeddings espec√≠ficos

### Melhorias Planejadas

- [ ] Suporte a mais tipos de contrato
- [ ] An√°lise de precedentes por regi√£o
- [ ] Integra√ß√£o com bases de dados jur√≠dicas
- [ ] ML para ranking de relev√¢ncia
- [ ] API GraphQL para consultas complexas